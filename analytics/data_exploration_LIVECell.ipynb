{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data exploration of LIVECell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "import os,inspect\n",
    "import pathlib2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "\n",
    "def check_noneffective_ids(df):\n",
    "    \"\"\"\n",
    "    check if the given data frame has NaN and return the rows with it if any, or else return nothing\n",
    "    :param df: input dataframe\n",
    "    :return: the non effective rows of the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    is_NaN = df.isnull()\n",
    "    row_has_NaN = is_NaN.any(axis=1)\n",
    "    rows_with_NaN = df[row_has_NaN]\n",
    "    len_rows_with_NaN = rows_with_NaN.shape[0]\n",
    "    if len_rows_with_NaN != 0:\n",
    "        print(f\"there are {len_rows_with_NaN} non effective rows.\")\n",
    "        return rows_with_NaN\n",
    "    else:\n",
    "        print(\"the rows available are all effective, i.e., without NaNs.\")\n",
    "        return None\n",
    "\n",
    "def check_meta_images_ds(df):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "def check_meta_annots_ds(df):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define relevant paths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentdir:  F:\\Kaggle\\sartorius_cell_instance_segmentation\\code\\rkx_cell_is\\analytics\n",
      "parentdir:  F:\\Kaggle\\sartorius_cell_instance_segmentation\\code\\rkx_cell_is\n"
     ]
    }
   ],
   "source": [
    "current_dir = pathlib2.Path.cwd()\n",
    "# current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "print(\"currentdir: \", current_dir)\n",
    "project_dir = current_dir.parent\n",
    "print(\"project dir: \", project_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset dir:  F:\\Kaggle\\sartorius_cell_instance_segmentation\\code\\rkx_cell_is\\dataset\n",
      "livecell dataset dir:  F:\\Kaggle\\sartorius_cell_instance_segmentation\\code\\rkx_cell_is\\dataset\\LIVECell_dataset_2021\n",
      "the json file of training data meta info is: F:\\Kaggle\\sartorius_cell_instance_segmentation\\code\\rkx_cell_is\\dataset\\LIVECell_dataset_2021\\annotations\\LIVECell\\livecell_coco_train.json\n",
      "dict_keys(['images', 'annotations', 'categories', 'info', 'licenses'])\n"
     ]
    }
   ],
   "source": [
    "ds_path = project_dir / 'dataset'\n",
    "print(\"dataset dir: \", ds_path)\n",
    "livecell_ds_path = ds_path / 'LIVECell_dataset_2021'\n",
    "print(\"livecell dataset dir: \", livecell_ds_path)\n",
    "livecell_ds_annot_path, livecell_ds_imgs_path = [x for x in livecell_ds_path.iterdir() if x.is_dir()]\n",
    "\n",
    "livecell_train_meta_path = livecell_ds_annot_path / 'LIVECell' / 'livecell_coco_train.json'\n",
    "livecell_val_meta_path = livecell_ds_annot_path / 'LIVECell' / 'livecell_coco_val.json'\n",
    "livecell_test_meta_path = livecell_ds_annot_path / 'LIVECell' / 'livecell_coco_test.json'\n",
    "\n",
    "livecell_train_val_img_path = livecell_ds_imgs_path / 'livecell_train_val_images'\n",
    "livecell_test_img_path = livecell_ds_imgs_path / 'livecell_test_images'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training metadata exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'annotations', 'categories', 'info', 'licenses']) \n",
      "\n",
      "\n",
      "the type of images container:  <class 'list'>\n",
      "the first element of <list> images: \n",
      " {'id': 1, 'width': 704, 'height': 520, 'file_name': 'BT474_Phase_A3_2_00d04h00m_3.tif', 'original_filename': 'BT474_Phase_A3_2_00d04h00m_3.png', 'url': 'https://darwin.v7labs.com/api/images/870028/original'} \n",
      "\n",
      "\n",
      "the type of annotations container:  <class 'dict'>\n",
      "the first ten keys of <dict> annotations: \n",
      " ['2', '3', '4', '5', '6', '7', '8', '9', '10', '12']\n",
      "the first item has the key: \n",
      " 2 \n",
      "and the value: \n",
      "{'id': 2, 'image_id': 1, 'category_id': 1, 'segmentation': [[288.02, 305.63, 286.01, 298.87, 286.01, 295.4, 288.02, 290.1, 293.86, 287.91, 297.51, 287.73, 300.44, 289.01, 304.27, 292.48, 304.64, 295.04, 305.18, 297.77, 305.18, 300.7, 303.91, 302.52, 301.17, 305.26, 297.33, 307.45, 294.59, 307.45, 290.58, 308.0]], 'area': 307.4786000000313, 'bbox': [286.01, 287.73, 19.170000000000016, 20.269999999999982], 'iscrowd': 0} \n",
      "\n",
      "\n",
      "the type of info container:  <class 'dict'>\n",
      "the keys of <dict> info: \n",
      " dict_keys(['year', 'version', 'description', 'contributor', 'url', 'date_created']) \n",
      "\n",
      "\n",
      "the type of licenses container:  <class 'list'>\n",
      "the first element of <list> licenses: \n",
      " {'id': 1, 'name': 'Attribution-NonCommercial 4.0 International License', 'url': 'https://creativecommons.org/licenses/by-nc/4.0/'}\n"
     ]
    }
   ],
   "source": [
    "# Reading the json file including training metadata as a dict\n",
    "with open(livecell_train_meta_path) as json_train_data:\n",
    "    train_data = json.load(json_train_data)\n",
    "\n",
    "\n",
    "print(train_data.keys(), '\\n\\n')\n",
    "print('the type of images container: ', type(train_data['images']))\n",
    "print('the first element of <list> images: \\n', train_data['images'][0], '\\n\\n')\n",
    "print('the type of annotations container: ', type(train_data['annotations']))\n",
    "print('the first ten keys of <dict> annotations: \\n', list(train_data['annotations'].keys())[:10])\n",
    "print(f\"the first item has the key: \\n {list(train_data['annotations'].items())[0][0]} \\nand the value: \\n\"\n",
    "      f\"{list(train_data['annotations'].items())[0][1]} \\n\\n\")\n",
    "print('the type of info container: ', type(train_data['info']))\n",
    "print('the keys of <dict> info: \\n', train_data['info'].keys(), '\\n\\n')\n",
    "print('the type of licenses container: ', type(train_data['licenses']))\n",
    "print('the first element of <list> licenses: \\n', train_data['licenses'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1018576 keys in the annotation dict.\n",
      "True : The keys_arr out of keys of the annotation dict and id_arr out of the IDs in the annotation dict is elementwise equal.\n",
      "The first 100 IDs in the annotation dict:\n",
      "[  2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18  19  20\n",
      "  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102]\n"
     ]
    }
   ],
   "source": [
    "# more about the dict annotation\n",
    "\n",
    "print(f\"There are {len(train_data['annotations'].keys())} keys in the annotation dict.\")\n",
    "keys_arr = np.array(list(train_data['annotations'].keys())).astype(int)\n",
    "annot_values = list(train_data['annotations'].values())\n",
    "id_list = [x['id'] for x in annot_values]\n",
    "id_arr = np.array(id_list)\n",
    "print(np.allclose(keys_arr, id_arr), ': The keys_arr out of keys of the annotation dict and id_arr out of the IDs in the '\n",
    "                                     'annotation dict is elementwise equal.\\n')\n",
    "print('The first 100 IDs in the annotation dict:')\n",
    "print(id_arr[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metadata: images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "    id  width  height                         file_name  \\\n0    1    704     520  BT474_Phase_A3_2_00d04h00m_3.tif   \n1  133    704     520  BT474_Phase_C3_2_02d12h00m_4.tif   \n2  323    704     520  BT474_Phase_C3_1_01d16h00m_3.tif   \n3  498    704     520  BT474_Phase_C3_1_02d16h00m_4.tif   \n4  741    704     520  BT474_Phase_C3_1_04d00h00m_3.tif   \n\n                  original_filename  \\\n0  BT474_Phase_A3_2_00d04h00m_3.png   \n1  BT474_Phase_C3_2_02d12h00m_4.png   \n2  BT474_Phase_C3_1_01d16h00m_3.png   \n3  BT474_Phase_C3_1_02d16h00m_4.png   \n4  BT474_Phase_C3_1_04d00h00m_3.png   \n\n                                                 url  \n0  https://darwin.v7labs.com/api/images/870028/or...  \n1  https://darwin.v7labs.com/api/images/37512/ori...  \n2  https://darwin.v7labs.com/api/images/108155/or...  \n3  https://darwin.v7labs.com/api/images/108172/or...  \n4  https://darwin.v7labs.com/api/images/921711/or...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>width</th>\n      <th>height</th>\n      <th>file_name</th>\n      <th>original_filename</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>704</td>\n      <td>520</td>\n      <td>BT474_Phase_A3_2_00d04h00m_3.tif</td>\n      <td>BT474_Phase_A3_2_00d04h00m_3.png</td>\n      <td>https://darwin.v7labs.com/api/images/870028/or...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>133</td>\n      <td>704</td>\n      <td>520</td>\n      <td>BT474_Phase_C3_2_02d12h00m_4.tif</td>\n      <td>BT474_Phase_C3_2_02d12h00m_4.png</td>\n      <td>https://darwin.v7labs.com/api/images/37512/ori...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>323</td>\n      <td>704</td>\n      <td>520</td>\n      <td>BT474_Phase_C3_1_01d16h00m_3.tif</td>\n      <td>BT474_Phase_C3_1_01d16h00m_3.png</td>\n      <td>https://darwin.v7labs.com/api/images/108155/or...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>498</td>\n      <td>704</td>\n      <td>520</td>\n      <td>BT474_Phase_C3_1_02d16h00m_4.tif</td>\n      <td>BT474_Phase_C3_1_02d16h00m_4.png</td>\n      <td>https://darwin.v7labs.com/api/images/108172/or...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>741</td>\n      <td>704</td>\n      <td>520</td>\n      <td>BT474_Phase_C3_1_04d00h00m_3.tif</td>\n      <td>BT474_Phase_C3_1_04d00h00m_3.png</td>\n      <td>https://darwin.v7labs.com/api/images/921711/or...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_livecell_train_imgs_meta = pd.DataFrame.from_dict(train_data['images'])\n",
    "df_livecell_train_imgs_meta.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rows available are all effective, i.e., without NaNs.\n"
     ]
    }
   ],
   "source": [
    "check_noneffective_ids(df_livecell_train_imgs_meta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3253 items in the image meta dataframe\n",
      "there are 3253 unique images in the training dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {df_livecell_train_imgs_meta.shape[0]} items in the image meta dataframe\")\n",
    "ids_img_meta_arr = df_livecell_train_imgs_meta['id'].unique()\n",
    "print(f\"there are {ids_img_meta_arr.shape[0]} unique images in the training dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to the result of the following code block, the id column is sorted by size."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      1     133     323 ... 1587591 1588143 1588375]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ids_img_meta_arr_copy = ids_img_meta_arr.copy()\n",
    "ids_img_meta_arr_copy.sort()\n",
    "print(ids_img_meta_arr_copy)\n",
    "print(np.allclose(ids_img_meta_arr, ids_img_meta_arr_copy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metadata: annotations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "   id  image_id  category_id  \\\n2   2         1            1   \n3   3         1            1   \n4   4         1            1   \n5   5         1            1   \n6   6         1            1   \n\n                                        segmentation       area  \\\n2  [[288.02, 305.63, 286.01, 298.87, 286.01, 295....  307.47860   \n3  [[271.22, 323.34, 267.93, 322.61, 266.29, 320....  247.47555   \n4  [[284.91, 279.88, 289.85, 281.52, 293.31, 281....  245.22945   \n5  [[260.86, 327.64, 258.19, 325.63, 255.25, 324....  574.21305   \n6  [[241.75, 324.69, 239.61, 326.97, 236.27, 331....  296.31140   \n\n                                                bbox  iscrowd  \n2  [286.01, 287.73, 19.170000000000016, 20.269999...        0  \n3  [263.0, 304.9, 20.44999999999999, 18.439999999...        0  \n4  [275.42, 277.14, 23.91999999999996, 17.1600000...        0  \n5          [246.96, 280.72, 20.98999999999998, 54.0]        0  \n6        [229.45, 302.91, 22.590000000000003, 32.75]        0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>image_id</th>\n      <th>category_id</th>\n      <th>segmentation</th>\n      <th>area</th>\n      <th>bbox</th>\n      <th>iscrowd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[[288.02, 305.63, 286.01, 298.87, 286.01, 295....</td>\n      <td>307.47860</td>\n      <td>[286.01, 287.73, 19.170000000000016, 20.269999...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[[271.22, 323.34, 267.93, 322.61, 266.29, 320....</td>\n      <td>247.47555</td>\n      <td>[263.0, 304.9, 20.44999999999999, 18.439999999...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[[284.91, 279.88, 289.85, 281.52, 293.31, 281....</td>\n      <td>245.22945</td>\n      <td>[275.42, 277.14, 23.91999999999996, 17.1600000...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[[260.86, 327.64, 258.19, 325.63, 255.25, 324....</td>\n      <td>574.21305</td>\n      <td>[246.96, 280.72, 20.98999999999998, 54.0]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[[241.75, 324.69, 239.61, 326.97, 236.27, 331....</td>\n      <td>296.31140</td>\n      <td>[229.45, 302.91, 22.590000000000003, 32.75]</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dataframe of annotations dict\n",
    "\n",
    "df_livecell_train_annots_meta = pd.DataFrame.from_dict(train_data['annotations'], orient='index')\n",
    "df_livecell_train_annots_meta.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rows available are all effective, i.e., without NaNs.\n"
     ]
    }
   ],
   "source": [
    "check_noneffective_ids(df_livecell_train_annots_meta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1018576 unique ids in the training dataset\n",
      "there are 3253 unique images in the training dataset\n",
      "there are 1 unique categories in the training dataset\n",
      "there are 1 unique values of iscrowd in the training dataset\n"
     ]
    }
   ],
   "source": [
    "ids_arr = df_livecell_train_annots_meta['id'].unique()\n",
    "print(f\"there are {ids_arr.shape[0]} unique ids in the training dataset\")\n",
    "img_ids_arr = df_livecell_train_annots_meta['image_id'].unique()\n",
    "print(f\"there are {img_ids_arr.shape[0]} unique images in the training dataset\")\n",
    "category_ids_arr = df_livecell_train_annots_meta['category_id'].unique()\n",
    "print(f\"there are {category_ids_arr.shape[0]} unique categories in the training dataset\")\n",
    "iscrowd_arr = df_livecell_train_annots_meta['iscrowd'].unique()\n",
    "print(f\"there are {iscrowd_arr.shape[0]} unique values of iscrowd in the training dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metadata: info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "{'year': '2020',\n 'version': '1.0',\n 'description': 'LIVECell 2021 Dataset',\n 'contributor': 'Sartorius',\n 'url': 'https://osf.io/6kang/?view_only=da0516e9189b4dbdbf018475113ed343',\n 'date_created': '2021/01/19'}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['info']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metadata: licenses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'id': 1,\n  'name': 'Attribution-NonCommercial 4.0 International License',\n  'url': 'https://creativecommons.org/licenses/by-nc/4.0/'}]"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['licenses']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation metadata exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing metadata exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}